{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import sklearn.metrics as metrics\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player                        object\n",
      "Rank                         float64\n",
      "Sets_Won                     float64\n",
      "Games_Won                      int64\n",
      "Aces                         float64\n",
      "DoubleFaults                 float64\n",
      "FirstServes_Won              float64\n",
      "FirstServes_In               float64\n",
      "SecondServes_Won             float64\n",
      "SecondServes_In              float64\n",
      "BreakPoints_Won              float64\n",
      "BreakPoints                  float64\n",
      "ReturnPoints_Won             float64\n",
      "ReturnPoints_Faced           float64\n",
      "TotalPoints_Won                int64\n",
      "won_game?                      int64\n",
      "FirstServes_ratio            float64\n",
      "SecondServes_ratio           float64\n",
      "BreakPoints_ratio            float64\n",
      "ReturnPoints_ratio           float64\n",
      "datetime              datetime64[ns]\n",
      "year                           int64\n",
      "Tournament                    object\n",
      "Round_Description             object\n",
      "Court_Surface                 object\n",
      "Total_Serves                 float64\n",
      "Aces%                        float64\n",
      "ServesWon%                   float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Sets_Won</th>\n",
       "      <th>Games_Won</th>\n",
       "      <th>Aces</th>\n",
       "      <th>DoubleFaults</th>\n",
       "      <th>FirstServes_Won</th>\n",
       "      <th>FirstServes_In</th>\n",
       "      <th>SecondServes_Won</th>\n",
       "      <th>SecondServes_In</th>\n",
       "      <th>...</th>\n",
       "      <th>BreakPoints_ratio</th>\n",
       "      <th>ReturnPoints_ratio</th>\n",
       "      <th>datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Round_Description</th>\n",
       "      <th>Court_Surface</th>\n",
       "      <th>Total_Serves</th>\n",
       "      <th>Aces%</th>\n",
       "      <th>ServesWon%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edouard Roger-Vasselin</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>First Round</td>\n",
       "      <td>Hard</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dudi Sela</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>First Round</td>\n",
       "      <td>Hard</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go Soeda</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>First Round</td>\n",
       "      <td>Hard</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.058252</td>\n",
       "      <td>0.650485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yuki Bhambri</td>\n",
       "      <td>345.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>First Round</td>\n",
       "      <td>Hard</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.673913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yuichi Sugita</td>\n",
       "      <td>235.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>First Round</td>\n",
       "      <td>Hard</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Player   Rank  Sets_Won  Games_Won  Aces  DoubleFaults  \\\n",
       "0  Edouard Roger-Vasselin  106.0       2.0         12   5.0           2.0   \n",
       "1               Dudi Sela   83.0       2.0         12   2.0           0.0   \n",
       "2                Go Soeda  120.0       2.0         19   6.0           1.0   \n",
       "3            Yuki Bhambri  345.0       2.0         12   1.0           2.0   \n",
       "4           Yuichi Sugita  235.0       2.0         12   3.0           1.0   \n",
       "\n",
       "   FirstServes_Won  FirstServes_In  SecondServes_Won  SecondServes_In  \\\n",
       "0             22.0            30.0              12.0             19.0   \n",
       "1             14.0            17.0              11.0             16.0   \n",
       "2             48.0            64.0              19.0             39.0   \n",
       "3             22.0            29.0               9.0             17.0   \n",
       "4             37.0            51.0              11.0             27.0   \n",
       "\n",
       "      ...      BreakPoints_ratio  ReturnPoints_ratio   datetime  year  \\\n",
       "0     ...               0.571429            0.423729 2012-01-02  2012   \n",
       "1     ...               0.428571            0.620690 2012-01-02  2012   \n",
       "2     ...               0.454545            0.400000 2012-01-02  2012   \n",
       "3     ...               0.384615            0.548387 2012-01-02  2012   \n",
       "4     ...               0.428571            0.407407 2012-01-02  2012   \n",
       "\n",
       "   Tournament  Round_Description  Court_Surface  Total_Serves     Aces%  \\\n",
       "0     Chennai        First Round           Hard          49.0  0.102041   \n",
       "1     Chennai        First Round           Hard          33.0  0.060606   \n",
       "2     Chennai        First Round           Hard         103.0  0.058252   \n",
       "3     Chennai        First Round           Hard          46.0  0.021739   \n",
       "4     Chennai        First Round           Hard          78.0  0.038462   \n",
       "\n",
       "   ServesWon%  \n",
       "0    0.693878  \n",
       "1    0.757576  \n",
       "2    0.650485  \n",
       "3    0.673913  \n",
       "4    0.615385  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (11,12,13,14,17,18,24,25,26,27,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner                        object\n",
      "Loser                         object\n",
      "Tournament                    object\n",
      "Tournament_Date               object\n",
      "Court_Surface                 object\n",
      "Round_Description             object\n",
      "Winner_Rank                  float64\n",
      "Loser_Rank                   float64\n",
      "Retirement_Ind                 int64\n",
      "Winner_Sets_Won              float64\n",
      "Winner_Games_Won               int64\n",
      "Winner_Aces                  float64\n",
      "Winner_DoubleFaults          float64\n",
      "Winner_FirstServes_Won       float64\n",
      "Winner_FirstServes_In        float64\n",
      "Winner_SecondServes_Won      float64\n",
      "Winner_SecondServes_In       float64\n",
      "Winner_BreakPoints_Won       float64\n",
      "Winner_BreakPoints           float64\n",
      "Winner_ReturnPoints_Won      float64\n",
      "Winner_ReturnPoints_Faced    float64\n",
      "Winner_TotalPoints_Won         int64\n",
      "Loser_Sets_Won               float64\n",
      "Loser_Games_Won                int64\n",
      "Loser_Aces                   float64\n",
      "Loser_DoubleFaults           float64\n",
      "Loser_FirstServes_Won        float64\n",
      "Loser_FirstServes_In         float64\n",
      "Loser_SecondServes_Won       float64\n",
      "Loser_SecondServes_In        float64\n",
      "Loser_BreakPoints_Won        float64\n",
      "Loser_BreakPoints            float64\n",
      "Loser_ReturnPoints_Won       float64\n",
      "Loser_ReturnPoints_Faced     float64\n",
      "Loser_TotalPoints_Won          int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>Loser</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Tournament_Date</th>\n",
       "      <th>Court_Surface</th>\n",
       "      <th>Round_Description</th>\n",
       "      <th>Winner_Rank</th>\n",
       "      <th>Loser_Rank</th>\n",
       "      <th>Retirement_Ind</th>\n",
       "      <th>Winner_Sets_Won</th>\n",
       "      <th>...</th>\n",
       "      <th>Loser_FirstServes_In</th>\n",
       "      <th>Loser_SecondServes_Won</th>\n",
       "      <th>Loser_SecondServes_In</th>\n",
       "      <th>Loser_BreakPoints_Won</th>\n",
       "      <th>Loser_BreakPoints</th>\n",
       "      <th>Loser_ReturnPoints_Won</th>\n",
       "      <th>Loser_ReturnPoints_Faced</th>\n",
       "      <th>Loser_TotalPoints_Won</th>\n",
       "      <th>datetime</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edouard Roger-Vasselin</td>\n",
       "      <td>Eric Prodon</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>02-Jan-12</td>\n",
       "      <td>Hard</td>\n",
       "      <td>First Round</td>\n",
       "      <td>106.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dudi Sela</td>\n",
       "      <td>Fabio Fognini</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>02-Jan-12</td>\n",
       "      <td>Hard</td>\n",
       "      <td>First Round</td>\n",
       "      <td>83.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go Soeda</td>\n",
       "      <td>Frederico Gil</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>02-Jan-12</td>\n",
       "      <td>Hard</td>\n",
       "      <td>First Round</td>\n",
       "      <td>120.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yuki Bhambri</td>\n",
       "      <td>Karol Beck</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>02-Jan-12</td>\n",
       "      <td>Hard</td>\n",
       "      <td>First Round</td>\n",
       "      <td>345.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>43</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yuichi Sugita</td>\n",
       "      <td>Olivier Rochus</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>02-Jan-12</td>\n",
       "      <td>Hard</td>\n",
       "      <td>First Round</td>\n",
       "      <td>235.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Winner           Loser Tournament Tournament_Date  \\\n",
       "0  Edouard Roger-Vasselin     Eric Prodon    Chennai       02-Jan-12   \n",
       "1               Dudi Sela   Fabio Fognini    Chennai       02-Jan-12   \n",
       "2                Go Soeda   Frederico Gil    Chennai       02-Jan-12   \n",
       "3            Yuki Bhambri      Karol Beck    Chennai       02-Jan-12   \n",
       "4           Yuichi Sugita  Olivier Rochus    Chennai       02-Jan-12   \n",
       "\n",
       "  Court_Surface Round_Description  Winner_Rank  Loser_Rank  Retirement_Ind  \\\n",
       "0          Hard       First Round        106.0        97.0               0   \n",
       "1          Hard       First Round         83.0        48.0               0   \n",
       "2          Hard       First Round        120.0       102.0               0   \n",
       "3          Hard       First Round        345.0       101.0               0   \n",
       "4          Hard       First Round        235.0        67.0               0   \n",
       "\n",
       "   Winner_Sets_Won  ...   Loser_FirstServes_In  Loser_SecondServes_Won  \\\n",
       "0              2.0  ...                   33.0                    13.0   \n",
       "1              2.0  ...                   32.0                     5.0   \n",
       "2              2.0  ...                   70.0                    18.0   \n",
       "3              2.0  ...                   33.0                    13.0   \n",
       "4              2.0  ...                   32.0                    13.0   \n",
       "\n",
       "   Loser_SecondServes_In  Loser_BreakPoints_Won  Loser_BreakPoints  \\\n",
       "0                   26.0                    1.0                3.0   \n",
       "1                   26.0                    0.0                1.0   \n",
       "2                   35.0                    2.0                4.0   \n",
       "3                   29.0                    2.0                3.0   \n",
       "4                   22.0                    1.0                7.0   \n",
       "\n",
       "   Loser_ReturnPoints_Won  Loser_ReturnPoints_Faced  Loser_TotalPoints_Won  \\\n",
       "0                    15.0                      49.0                     49   \n",
       "1                     8.0                      33.0                     30   \n",
       "2                    36.0                     103.0                     99   \n",
       "3                    15.0                      46.0                     43   \n",
       "4                    30.0                      78.0                     62   \n",
       "\n",
       "    datetime  year  \n",
       "0 2012-01-02  2012  \n",
       "1 2012-01-02  2012  \n",
       "2 2012-01-02  2012  \n",
       "3 2012-01-02  2012  \n",
       "4 2012-01-02  2012  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4999257609502598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player1</th>\n",
       "      <th>Player1Win</th>\n",
       "      <th>Player2</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5893</th>\n",
       "      <td>Edouard Roger-Vasselin</td>\n",
       "      <td>1</td>\n",
       "      <td>Albert Ramos-Vinolas</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>Guillermo Garcia-Lopez</td>\n",
       "      <td>1</td>\n",
       "      <td>Aleksandr Nedovyesov</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>Henri Laaksonen</td>\n",
       "      <td>0</td>\n",
       "      <td>Aljaz Bedene</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>Jiri Vesely</td>\n",
       "      <td>1</td>\n",
       "      <td>Jeevan Nedunchezhiyan</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5897</th>\n",
       "      <td>Benjamin Becker</td>\n",
       "      <td>1</td>\n",
       "      <td>Julian Reister</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Player1  Player1Win                Player2   datetime\n",
       "5893  Edouard Roger-Vasselin           1   Albert Ramos-Vinolas 2014-01-01\n",
       "5894  Guillermo Garcia-Lopez           1   Aleksandr Nedovyesov 2014-01-01\n",
       "5895         Henri Laaksonen           0           Aljaz Bedene 2014-01-01\n",
       "5896             Jiri Vesely           1  Jeevan Nedunchezhiyan 2014-01-01\n",
       "5897         Benjamin Becker           1         Julian Reister 2014-01-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputfolder = 'data'\n",
    "datadf = pd.read_csv(os.path.join(inputfolder,\"mens_match_data.csv\"))\n",
    "datadf['datetime'] = pd.to_datetime(datadf['datetime'])\n",
    "with open(os.path.join(inputfolder,'datacolumns.txt'),'r') as f:\n",
    "    content = f.readlines()\n",
    "datacols = [x.strip() for x in content]\n",
    "print(datadf.dtypes)\n",
    "display(datadf.head())\n",
    "\n",
    "atpdata = pd.read_csv(os.path.join(inputfolder,\"ATP_matches.csv\"))\n",
    "cols = atpdata.drop(['Winner','Loser','Tournament','Tournament_Date','Court_Surface','Round_Description'],axis=1).columns\n",
    "for col in cols:\n",
    "    atpdata.loc[:,col]=pd.to_numeric(atpdata[col],errors='coerce')\n",
    "print(atpdata.dtypes)\n",
    "atpdata['datetime'] = pd.to_datetime(atpdata['Tournament_Date'])\n",
    "atpdata['year'] = pd.DatetimeIndex(atpdata['datetime']).year\n",
    "def fillrank(row,col,ATPframe):\n",
    "    if np.isnan(row[col]):\n",
    "            year = row['year']\n",
    "            tournament = row['Tournament']\n",
    "            surface = row['Court_Surface']\n",
    "            yeardf = ATPframe[ATPframe['year']==year] #i can do this slicing in one line, but im doing in two to allow for easier debugging\n",
    "            tourndf = ATPframe[(ATPframe['Tournament']==tournament)&(ATPframe['Court_Surface']==surface)]\n",
    "            maxrank = int(max([tourndf['Winner_Rank'].max(),tourndf['Loser_Rank'].max()]))\n",
    "            return maxrank+1\n",
    "    else:\n",
    "        return row[col]\n",
    "atpdata.loc[:,'Winner_Rank'] = atpdata.apply(fillrank,axis=1,args=('Winner_Rank',atpdata))\n",
    "atpdata.loc[:,'Loser_Rank'] = atpdata.apply(fillrank,axis=1,args=('Loser_Rank',atpdata))\n",
    "\n",
    "display(atpdata.head())\n",
    "\n",
    "#only going to use matches from 2014 onwards, not ussing matches from 2012-13 so we have enough historic data for matches in 2014\n",
    "atpHardOnly = atpdata.loc[(atpdata['Court_Surface']=='Hard')&(atpdata['year']>2013),['Winner','Loser','datetime']]\n",
    "frame1,frame2 = train_test_split(atpHardOnly,test_size=.5)\n",
    "frame1.columns = ['Player1','Player2','datetime']\n",
    "frame1['Player1Win'] = 1\n",
    "\n",
    "frame2.columns = ['Player2','Player1','datetime']\n",
    "frame2['Player1Win'] = 0\n",
    "\n",
    "traininput = pd.concat([frame1,frame2])\n",
    "traininput.sort_index(inplace=True)\n",
    "print(traininput['Player1Win'].mean())\n",
    "display(traininput.head())\n",
    "\n",
    "# splitting into X and Y\n",
    "X = traininput.drop('Player1Win',axis=1)\n",
    "Y = traininput['Player1Win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player1                                      object\n",
      "Player2                                      object\n",
      "Rank_diff                                   float64\n",
      "ytd_Aces%_Stddev_diff                       float64\n",
      "ytd_ServesWon%_Stddev_diff                  float64\n",
      "careeravg_Sets_Won_diff                     float64\n",
      "careeravg_Games_Won_diff                    float64\n",
      "careeravg_Aces_diff                         float64\n",
      "careeravg_DoubleFaults_diff                 float64\n",
      "careeravg_FirstServes_Won_diff              float64\n",
      "careeravg_FirstServes_In_diff               float64\n",
      "careeravg_SecondServes_Won_diff             float64\n",
      "careeravg_SecondServes_In_diff              float64\n",
      "careeravg_BreakPoints_Won_diff              float64\n",
      "careeravg_BreakPoints_diff                  float64\n",
      "careeravg_ReturnPoints_Won_diff             float64\n",
      "careeravg_ReturnPoints_Faced_diff           float64\n",
      "careeravg_TotalPoints_Won_diff              float64\n",
      "careeravg_won_game?_diff                    float64\n",
      "careeravg_FirstServes_ratio_diff            float64\n",
      "careeravg_SecondServes_ratio_diff           float64\n",
      "careeravg_BreakPoints_ratio_diff            float64\n",
      "careeravg_ReturnPoints_ratio_diff           float64\n",
      "careeravg_Total_Serves_diff                 float64\n",
      "careeravg_Aces%_diff                        float64\n",
      "careeravg_ServesWon%_diff                   float64\n",
      "ytd_Sets_Won_diff                           float64\n",
      "ytd_Games_Won_diff                          float64\n",
      "ytd_Aces_diff                               float64\n",
      "ytd_DoubleFaults_diff                       float64\n",
      "ytd_FirstServes_Won_diff                    float64\n",
      "ytd_FirstServes_In_diff                     float64\n",
      "ytd_SecondServes_Won_diff                   float64\n",
      "ytd_SecondServes_In_diff                    float64\n",
      "ytd_BreakPoints_Won_diff                    float64\n",
      "ytd_BreakPoints_diff                        float64\n",
      "ytd_ReturnPoints_Won_diff                   float64\n",
      "ytd_ReturnPoints_Faced_diff                 float64\n",
      "ytd_TotalPoints_Won_diff                    float64\n",
      "ytd_won_game?_diff                          float64\n",
      "ytd_FirstServes_ratio_diff                  float64\n",
      "ytd_SecondServes_ratio_diff                 float64\n",
      "ytd_BreakPoints_ratio_diff                  float64\n",
      "ytd_ReturnPoints_ratio_diff                 float64\n",
      "ytd_Total_Serves_diff                       float64\n",
      "ytd_Aces%_diff                              float64\n",
      "ytd_ServesWon%_diff                         float64\n",
      "Player1fg                                      bool\n",
      "Player2fg                                      bool\n",
      "datetime                             datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#defining preprocessing functions (from wrangleDataAttempt2)\n",
    "def days_difference(date1,date2):\n",
    "            diff = date2-date1\n",
    "            return diff.days\n",
    "\n",
    "def get_player_stats(inputframe,harddf,datacols,playercol):\n",
    "    #idea is to pass a panda dataframe with columns [playername, tournamentdate] and be able to return a dataframe with the stats\n",
    "    length = inputframe.shape[0]\n",
    "    historicnames = ['careeravg_'+x for x in datacols]\n",
    "    ytdnames = ['ytd_'+x for x in datacols]\n",
    "    colnames = [playercol,'datetime','Rank','ytd_Aces%_Stddev','ytd_ServesWon%_Stddev'] + historicnames+ytdnames\n",
    "    outputframe = pd.DataFrame(index=range(0,length),columns=colnames)\n",
    "    outputframe.loc[:,playercol] = inputframe[playercol]\n",
    "    outputframe.loc[:,'datetime'] = inputframe['datetime']\n",
    "    for index in range(0,length):\n",
    "        #extract player name and date of game\n",
    "        row = inputframe.iloc[index,:]\n",
    "        playername = row[playercol]\n",
    "        date = row['datetime']\n",
    "        \n",
    "        #grab only data for that player before that date\n",
    "        tempdf = harddf[harddf['Player']==playername]\n",
    "        tempdf.loc[:,'timedelta'] = tempdf['datetime'].apply(days_difference,args=(date,))\n",
    "        tempdf = tempdf[tempdf['timedelta']>0]\n",
    "        if tempdf.empty:\n",
    "            continue\n",
    "        ytddf = tempdf.loc[tempdf['timedelta']<=365]\n",
    "#         display(ytddf.head())\n",
    "        currank = tempdf.loc[tempdf['timedelta'].idxmin(),'Rank']\n",
    "        historicframe = tempdf.loc[:,datacols].mean()\n",
    "        historicframe.index = historicnames\n",
    "        YTDframe = ytddf.loc[:,datacols].mean()\n",
    "        YTDframe.index = ytdnames\n",
    "        \n",
    "        #code for debugging NaNs\n",
    "#         if tempdf.isna().sum().sum()>0:\n",
    "#             print(playername)\n",
    "#             print(\"ytdframe shape: {}, missing values: {}\".format(ytddf.shape,ytddf.isna().sum().sum()))\n",
    "#             print(ytddf.isna().sum())\n",
    "#             print(\"careerdf shape: {}, missing values: {}\".format(tempdf.shape,tempdf.isna().sum().sum()))\n",
    "#             print(tempdf.isna().sum())\n",
    "\n",
    "        outputframe.loc[index,['Rank','ytd_Aces%_Stddev','ytd_ServesWon%_Stddev']] = [currank,ytddf['Aces%'].std(),ytddf['ServesWon%'].std()]\n",
    "        outputframe.loc[index,historicnames]=historicframe\n",
    "        outputframe.loc[index,ytdnames]=YTDframe\n",
    "    return outputframe\n",
    "\n",
    "def get_difference(frame1,frame2,colname=None, prefix1='',prefix2='',index1=None,index2=None):\n",
    "    #check if index between frames are identical, if not, reset both\n",
    "    idx_check = frame1.index.equals(frame2.index)\n",
    "    if not(idx_check):\n",
    "        frame1.reset_index(drop=True, inplace=True)\n",
    "        frame2.reset_index(drop=True, inplace=True)\n",
    "    if colname is None:\n",
    "        colname = frame1.columns\n",
    "    if frame1.shape[0] != frame2.shape[0]:\n",
    "        raise ValueError('both frames must contain the same number of rows/n Frame1: %{}/mn Frame2: %{}'.format(frame1.shape[0],frame2.shape[0]))\n",
    "    tempdiffcolnames = [x+\"_diff\" for x in colname]\n",
    "    diffcolnames = list()\n",
    "    if index1 is not None:\n",
    "        diffcolnames.append(index1)\n",
    "    if index2 is not None:\n",
    "        diffcolnames.append(index2)\n",
    "    diffcolnames = diffcolnames + tempdiffcolnames\n",
    "    if idx_check:\n",
    "        difframe = pd.DataFrame(index=frame1.index,columns=diffcolnames,data=0)\n",
    "    else:\n",
    "        difframe = pd.DataFrame(index=range(0,frame1.shape[0]),columns=diffcolnames,data=0)\n",
    "    if index1 is not None:\n",
    "        difframe[index1] = frame1[index1]\n",
    "    if index2 is not None:\n",
    "        difframe[index2] = frame2[index2]\n",
    "    for col in colname:\n",
    "        frame1name = prefix1+col\n",
    "        frame2name = prefix2+col\n",
    "        difframename = col+\"_diff\"\n",
    "        difframe[difframename]=frame1[frame1name] - frame2[frame2name]\n",
    "    return difframe\n",
    "\n",
    "def convert_to_data(inputframe,matchdata,datacols,player1colname=\"Player1\",player2colname=\"Player2\"):\n",
    "    inputframe.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    player1frame = inputframe.loc[:,[player1colname,'datetime']]\n",
    "    player2frame = inputframe.loc[:,[player2colname,'datetime']]\n",
    "    \n",
    "    player1df = get_player_stats(player1frame,matchdata,datacols,player1colname)\n",
    "    player2df = get_player_stats(player2frame,matchdata,datacols,player2colname)\n",
    "    \n",
    "    #append columns indicating whether this is a players first recorded Hard surface ATPgame (if it's their first game, Rank will return NaNs)\n",
    "    player1df['Player1fg'] = player1df['Rank'].isna()\n",
    "    player2df['Player2fg'] = player2df['Rank'].isna()\n",
    "    \n",
    "#     player1df = player1df[~player1df['Player1fg']].fillna(0)\n",
    "#     player2df = player2df[~player2df['Player2fg']].fillna(0)\n",
    "#     if player1df.isna().sum().sum() >0:\n",
    "#         display(player1df)\n",
    "    \n",
    "    \n",
    "    #for debugging purposes\n",
    "    if player1df.shape[0] != player2df.shape[0]:\n",
    "        return (player1df,player2df)\n",
    "    \n",
    "    newdatacols = player1df.drop([player1colname,'datetime','Player1fg'],axis=1).columns\n",
    "    outputdf = get_difference(player1df,player2df,newdatacols,index1=player1colname,index2=player2colname)\n",
    "    outputdf.loc[:,'Player1fg'] = player1df['Player1fg']\n",
    "    outputdf.loc[:,'Player2fg'] = player2df['Player2fg']\n",
    "    outputdf.loc[:,'datetime'] = player1df['datetime']\n",
    "    \n",
    "    return outputdf.infer_objects() #infer_objects soft converts object columns to their correct types\n",
    "\n",
    "# tempX = X.iloc[:15,:]\n",
    "# tempX = convert_to_data(tempX,datadf,datacols)\n",
    "# print(tempX.dtypes)\n",
    "\n",
    "X = convert_to_data(X,datadf,datacols)\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.341536</td>\n",
       "      <td>0.360438</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659737</td>\n",
       "      <td>0.017865</td>\n",
       "      <td>85</td>\n",
       "      <td>0.681432</td>\n",
       "      <td>0.681517</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>0.685578</td>\n",
       "      <td>0.680738</td>\n",
       "      <td>0.003812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.019204</td>\n",
       "      <td>0.098840</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659949</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>76</td>\n",
       "      <td>0.681432</td>\n",
       "      <td>0.682312</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.681003</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.006055</td>\n",
       "      <td>0.033567</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659101</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>123</td>\n",
       "      <td>0.681698</td>\n",
       "      <td>0.682312</td>\n",
       "      <td>0.674357</td>\n",
       "      <td>0.680011</td>\n",
       "      <td>0.686903</td>\n",
       "      <td>0.681056</td>\n",
       "      <td>0.004053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.958978</td>\n",
       "      <td>0.036129</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658464</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>145</td>\n",
       "      <td>0.681698</td>\n",
       "      <td>0.681517</td>\n",
       "      <td>0.672501</td>\n",
       "      <td>0.679480</td>\n",
       "      <td>0.686903</td>\n",
       "      <td>0.680420</td>\n",
       "      <td>0.004658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.966871</td>\n",
       "      <td>0.035490</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659313</td>\n",
       "      <td>0.017447</td>\n",
       "      <td>104</td>\n",
       "      <td>0.682493</td>\n",
       "      <td>0.681517</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.681056</td>\n",
       "      <td>0.004004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.973689</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659313</td>\n",
       "      <td>0.017447</td>\n",
       "      <td>104</td>\n",
       "      <td>0.682493</td>\n",
       "      <td>0.681517</td>\n",
       "      <td>0.673561</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>0.680738</td>\n",
       "      <td>0.003792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.073691</td>\n",
       "      <td>0.031479</td>\n",
       "      <td>0.029127</td>\n",
       "      <td>0.017501</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659313</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>104</td>\n",
       "      <td>0.683024</td>\n",
       "      <td>0.680191</td>\n",
       "      <td>0.674092</td>\n",
       "      <td>0.680276</td>\n",
       "      <td>0.686638</td>\n",
       "      <td>0.680844</td>\n",
       "      <td>0.004115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.008283</td>\n",
       "      <td>0.064716</td>\n",
       "      <td>0.011265</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659313</td>\n",
       "      <td>0.017310</td>\n",
       "      <td>104</td>\n",
       "      <td>0.681167</td>\n",
       "      <td>0.680986</td>\n",
       "      <td>0.674357</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>0.686638</td>\n",
       "      <td>0.680897</td>\n",
       "      <td>0.003899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.996657</td>\n",
       "      <td>0.057078</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659313</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>104</td>\n",
       "      <td>0.681963</td>\n",
       "      <td>0.682312</td>\n",
       "      <td>0.673031</td>\n",
       "      <td>0.680806</td>\n",
       "      <td>0.686638</td>\n",
       "      <td>0.680950</td>\n",
       "      <td>0.004427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.954129</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659313</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>104</td>\n",
       "      <td>0.681432</td>\n",
       "      <td>0.681252</td>\n",
       "      <td>0.673561</td>\n",
       "      <td>0.682131</td>\n",
       "      <td>0.687169</td>\n",
       "      <td>0.681109</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.966126</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659525</td>\n",
       "      <td>0.017657</td>\n",
       "      <td>95</td>\n",
       "      <td>0.681963</td>\n",
       "      <td>0.681517</td>\n",
       "      <td>0.673296</td>\n",
       "      <td>0.680011</td>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.680579</td>\n",
       "      <td>0.004165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.955068</td>\n",
       "      <td>0.040157</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659737</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>85</td>\n",
       "      <td>0.681698</td>\n",
       "      <td>0.680721</td>\n",
       "      <td>0.674092</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>0.687434</td>\n",
       "      <td>0.681056</td>\n",
       "      <td>0.004237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.965658</td>\n",
       "      <td>0.023849</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659737</td>\n",
       "      <td>0.017672</td>\n",
       "      <td>85</td>\n",
       "      <td>0.680637</td>\n",
       "      <td>0.682047</td>\n",
       "      <td>0.673561</td>\n",
       "      <td>0.680806</td>\n",
       "      <td>0.687434</td>\n",
       "      <td>0.680897</td>\n",
       "      <td>0.004426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.955837</td>\n",
       "      <td>0.045879</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659525</td>\n",
       "      <td>0.017223</td>\n",
       "      <td>95</td>\n",
       "      <td>0.680902</td>\n",
       "      <td>0.682047</td>\n",
       "      <td>0.673561</td>\n",
       "      <td>0.680806</td>\n",
       "      <td>0.687434</td>\n",
       "      <td>0.680950</td>\n",
       "      <td>0.004424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.960929</td>\n",
       "      <td>0.035833</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660373</td>\n",
       "      <td>0.017340</td>\n",
       "      <td>55</td>\n",
       "      <td>0.680902</td>\n",
       "      <td>0.681782</td>\n",
       "      <td>0.672766</td>\n",
       "      <td>0.680806</td>\n",
       "      <td>0.685578</td>\n",
       "      <td>0.680367</td>\n",
       "      <td>0.004181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.997243</td>\n",
       "      <td>0.029544</td>\n",
       "      <td>0.011485</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659949</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>76</td>\n",
       "      <td>0.680637</td>\n",
       "      <td>0.682047</td>\n",
       "      <td>0.672501</td>\n",
       "      <td>0.681071</td>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.680473</td>\n",
       "      <td>0.004431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.925443</td>\n",
       "      <td>0.052067</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659949</td>\n",
       "      <td>0.016142</td>\n",
       "      <td>76</td>\n",
       "      <td>0.696817</td>\n",
       "      <td>0.688146</td>\n",
       "      <td>0.682047</td>\n",
       "      <td>0.690350</td>\n",
       "      <td>0.696978</td>\n",
       "      <td>0.690868</td>\n",
       "      <td>0.005625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.039359</td>\n",
       "      <td>0.055642</td>\n",
       "      <td>0.012437</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660373</td>\n",
       "      <td>0.015960</td>\n",
       "      <td>55</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.687351</td>\n",
       "      <td>0.682578</td>\n",
       "      <td>0.688229</td>\n",
       "      <td>0.696713</td>\n",
       "      <td>0.690284</td>\n",
       "      <td>0.005529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.919741</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>0.011638</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661434</td>\n",
       "      <td>0.015912</td>\n",
       "      <td>19</td>\n",
       "      <td>0.694960</td>\n",
       "      <td>0.687351</td>\n",
       "      <td>0.683373</td>\n",
       "      <td>0.689820</td>\n",
       "      <td>0.696713</td>\n",
       "      <td>0.690443</td>\n",
       "      <td>0.004892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.867748</td>\n",
       "      <td>0.071182</td>\n",
       "      <td>0.018040</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661222</td>\n",
       "      <td>0.014903</td>\n",
       "      <td>25</td>\n",
       "      <td>0.695756</td>\n",
       "      <td>0.687881</td>\n",
       "      <td>0.682578</td>\n",
       "      <td>0.687964</td>\n",
       "      <td>0.696978</td>\n",
       "      <td>0.690231</td>\n",
       "      <td>0.005390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.856036</td>\n",
       "      <td>0.057911</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661646</td>\n",
       "      <td>0.016404</td>\n",
       "      <td>14</td>\n",
       "      <td>0.694960</td>\n",
       "      <td>0.687616</td>\n",
       "      <td>0.682578</td>\n",
       "      <td>0.690085</td>\n",
       "      <td>0.695917</td>\n",
       "      <td>0.690231</td>\n",
       "      <td>0.004902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.845549</td>\n",
       "      <td>0.053887</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660161</td>\n",
       "      <td>0.014490</td>\n",
       "      <td>65</td>\n",
       "      <td>0.694695</td>\n",
       "      <td>0.687351</td>\n",
       "      <td>0.682047</td>\n",
       "      <td>0.690615</td>\n",
       "      <td>0.696182</td>\n",
       "      <td>0.690178</td>\n",
       "      <td>0.005114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.836832</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>0.012442</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660798</td>\n",
       "      <td>0.015648</td>\n",
       "      <td>40</td>\n",
       "      <td>0.695491</td>\n",
       "      <td>0.687616</td>\n",
       "      <td>0.682047</td>\n",
       "      <td>0.687699</td>\n",
       "      <td>0.696448</td>\n",
       "      <td>0.689860</td>\n",
       "      <td>0.005401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.893318</td>\n",
       "      <td>0.026080</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659949</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>76</td>\n",
       "      <td>0.696021</td>\n",
       "      <td>0.686820</td>\n",
       "      <td>0.682578</td>\n",
       "      <td>0.688759</td>\n",
       "      <td>0.695917</td>\n",
       "      <td>0.690019</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.030014</td>\n",
       "      <td>0.089796</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661434</td>\n",
       "      <td>0.015371</td>\n",
       "      <td>19</td>\n",
       "      <td>0.695225</td>\n",
       "      <td>0.687086</td>\n",
       "      <td>0.682312</td>\n",
       "      <td>0.689290</td>\n",
       "      <td>0.696713</td>\n",
       "      <td>0.690125</td>\n",
       "      <td>0.005299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.911362</td>\n",
       "      <td>0.085838</td>\n",
       "      <td>0.012429</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661434</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>19</td>\n",
       "      <td>0.695756</td>\n",
       "      <td>0.685760</td>\n",
       "      <td>0.682578</td>\n",
       "      <td>0.688229</td>\n",
       "      <td>0.696448</td>\n",
       "      <td>0.689754</td>\n",
       "      <td>0.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.886410</td>\n",
       "      <td>0.037560</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660161</td>\n",
       "      <td>0.015990</td>\n",
       "      <td>65</td>\n",
       "      <td>0.696021</td>\n",
       "      <td>0.686555</td>\n",
       "      <td>0.680986</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>0.696448</td>\n",
       "      <td>0.689807</td>\n",
       "      <td>0.005860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.844241</td>\n",
       "      <td>0.036983</td>\n",
       "      <td>0.016660</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661010</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>30</td>\n",
       "      <td>0.695756</td>\n",
       "      <td>0.687616</td>\n",
       "      <td>0.681517</td>\n",
       "      <td>0.688494</td>\n",
       "      <td>0.696448</td>\n",
       "      <td>0.689966</td>\n",
       "      <td>0.005561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.932203</td>\n",
       "      <td>0.080452</td>\n",
       "      <td>0.019660</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661646</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>14</td>\n",
       "      <td>0.695756</td>\n",
       "      <td>0.687616</td>\n",
       "      <td>0.681252</td>\n",
       "      <td>0.690085</td>\n",
       "      <td>0.697243</td>\n",
       "      <td>0.690390</td>\n",
       "      <td>0.005780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.906701</td>\n",
       "      <td>0.078782</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659949</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>76</td>\n",
       "      <td>0.695491</td>\n",
       "      <td>0.688146</td>\n",
       "      <td>0.682047</td>\n",
       "      <td>0.688494</td>\n",
       "      <td>0.697508</td>\n",
       "      <td>0.690337</td>\n",
       "      <td>0.005566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>15.199112</td>\n",
       "      <td>0.150649</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636826</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>526</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984619</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.980647</td>\n",
       "      <td>0.983828</td>\n",
       "      <td>0.982605</td>\n",
       "      <td>0.001439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>15.062806</td>\n",
       "      <td>0.128131</td>\n",
       "      <td>0.018454</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636826</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>526</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.980912</td>\n",
       "      <td>0.983563</td>\n",
       "      <td>0.982658</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>14.912100</td>\n",
       "      <td>0.122142</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643403</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>442</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.981702</td>\n",
       "      <td>0.980912</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982658</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>15.039356</td>\n",
       "      <td>0.104856</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633857</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>556</td>\n",
       "      <td>0.981432</td>\n",
       "      <td>0.984619</td>\n",
       "      <td>0.981968</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.983828</td>\n",
       "      <td>0.982605</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>15.038669</td>\n",
       "      <td>0.075118</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642554</td>\n",
       "      <td>0.013320</td>\n",
       "      <td>457</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.981968</td>\n",
       "      <td>0.980912</td>\n",
       "      <td>0.983828</td>\n",
       "      <td>0.982658</td>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>14.967315</td>\n",
       "      <td>0.091474</td>\n",
       "      <td>0.021661</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639160</td>\n",
       "      <td>0.014441</td>\n",
       "      <td>492</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.981968</td>\n",
       "      <td>0.980647</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982658</td>\n",
       "      <td>0.001579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>15.127351</td>\n",
       "      <td>0.085286</td>\n",
       "      <td>0.023698</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643615</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>436</td>\n",
       "      <td>0.981432</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.981968</td>\n",
       "      <td>0.980912</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982658</td>\n",
       "      <td>0.001552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>15.219083</td>\n",
       "      <td>0.107111</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.019222</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635766</td>\n",
       "      <td>0.007073</td>\n",
       "      <td>540</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.981968</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982764</td>\n",
       "      <td>0.001453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>15.067023</td>\n",
       "      <td>0.136902</td>\n",
       "      <td>0.020065</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641493</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>469</td>\n",
       "      <td>0.981432</td>\n",
       "      <td>0.984619</td>\n",
       "      <td>0.981968</td>\n",
       "      <td>0.980647</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982552</td>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>15.003582</td>\n",
       "      <td>0.074763</td>\n",
       "      <td>0.022695</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639796</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>488</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>15.117485</td>\n",
       "      <td>0.105014</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638736</td>\n",
       "      <td>0.011027</td>\n",
       "      <td>501</td>\n",
       "      <td>0.981432</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982764</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>15.316455</td>\n",
       "      <td>0.156335</td>\n",
       "      <td>0.023665</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637463</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>513</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.980912</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982764</td>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>15.244908</td>\n",
       "      <td>0.152797</td>\n",
       "      <td>0.022263</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642978</td>\n",
       "      <td>0.012395</td>\n",
       "      <td>449</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.981968</td>\n",
       "      <td>0.980912</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982711</td>\n",
       "      <td>0.001513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>15.163302</td>\n",
       "      <td>0.067038</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636402</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>531</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.981968</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982764</td>\n",
       "      <td>0.001453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>22.360932</td>\n",
       "      <td>0.139307</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636402</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>531</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>22.414212</td>\n",
       "      <td>0.141556</td>\n",
       "      <td>0.028920</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634705</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>546</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>22.564410</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.026696</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636402</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>531</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>22.314797</td>\n",
       "      <td>0.165718</td>\n",
       "      <td>0.030094</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640857</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>476</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>22.426342</td>\n",
       "      <td>0.139849</td>\n",
       "      <td>0.039727</td>\n",
       "      <td>0.024441</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643190</td>\n",
       "      <td>0.013392</td>\n",
       "      <td>446</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>22.408960</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>0.028888</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631735</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>570</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>22.429595</td>\n",
       "      <td>0.112651</td>\n",
       "      <td>0.032670</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638948</td>\n",
       "      <td>0.014811</td>\n",
       "      <td>496</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>22.529099</td>\n",
       "      <td>0.109697</td>\n",
       "      <td>0.030101</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634705</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>546</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>22.436018</td>\n",
       "      <td>0.114281</td>\n",
       "      <td>0.028484</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637251</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>520</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>22.549938</td>\n",
       "      <td>0.088905</td>\n",
       "      <td>0.038344</td>\n",
       "      <td>0.015821</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633008</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>563</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>22.536223</td>\n",
       "      <td>0.099585</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634281</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>551</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>22.495052</td>\n",
       "      <td>0.109282</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633220</td>\n",
       "      <td>0.013721</td>\n",
       "      <td>560</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>22.926456</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635766</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>540</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>23.337700</td>\n",
       "      <td>0.291573</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634069</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>553</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>23.142279</td>\n",
       "      <td>0.585276</td>\n",
       "      <td>0.029055</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637251</td>\n",
       "      <td>0.009889</td>\n",
       "      <td>520</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>21.512484</td>\n",
       "      <td>0.390384</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634493</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>549</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         3.341536      0.360438         0.019263        0.008574   \n",
       "1         4.019204      0.098840         0.006438        0.003683   \n",
       "2         4.006055      0.033567         0.007246        0.005501   \n",
       "3         3.958978      0.036129         0.011230        0.006162   \n",
       "4         3.966871      0.035490         0.012077        0.004209   \n",
       "5         3.973689      0.006946         0.008025        0.004012   \n",
       "6         4.073691      0.031479         0.029127        0.017501   \n",
       "7         4.008283      0.064716         0.011265        0.004485   \n",
       "8         3.996657      0.057078         0.012841        0.004679   \n",
       "9         3.954129      0.025918         0.010435        0.000810   \n",
       "10        3.966126      0.008223         0.012037        0.004010   \n",
       "11        3.955068      0.040157         0.009636        0.000803   \n",
       "12        3.965658      0.023849         0.012035        0.008603   \n",
       "13        3.955837      0.045879         0.008021        0.003105   \n",
       "14        3.960929      0.035833         0.008950        0.004102   \n",
       "15        3.997243      0.029544         0.011485        0.004456   \n",
       "16        7.925443      0.052067         0.016018        0.007009   \n",
       "17        8.039359      0.055642         0.012437        0.004818   \n",
       "18        7.919741      0.070793         0.011638        0.003201   \n",
       "19        7.867748      0.071182         0.018040        0.006720   \n",
       "20        7.856036      0.057911         0.013240        0.003930   \n",
       "21        7.845549      0.053887         0.010430        0.000801   \n",
       "22        7.836832      0.051716         0.012442        0.002946   \n",
       "23        7.893318      0.026080         0.012048        0.003108   \n",
       "24        8.030014      0.089796         0.013643        0.004474   \n",
       "25        7.911362      0.085838         0.012429        0.003886   \n",
       "26        7.886410      0.037560         0.010462        0.000788   \n",
       "27        7.844241      0.036983         0.016660        0.007223   \n",
       "28        7.932203      0.080452         0.019660        0.006391   \n",
       "29        7.906701      0.078782         0.013640        0.004473   \n",
       "..             ...           ...              ...             ...   \n",
       "546      15.199112      0.150649         0.018686        0.003353   \n",
       "547      15.062806      0.128131         0.018454        0.003449   \n",
       "548      14.912100      0.122142         0.018054        0.003104   \n",
       "549      15.039356      0.104856         0.022079        0.006487   \n",
       "550      15.038669      0.075118         0.023674        0.004464   \n",
       "551      14.967315      0.091474         0.021661        0.003207   \n",
       "552      15.127351      0.085286         0.023698        0.007208   \n",
       "553      15.219083      0.107111         0.029883        0.019222   \n",
       "554      15.067023      0.136902         0.020065        0.000007   \n",
       "555      15.003582      0.074763         0.022695        0.005270   \n",
       "556      15.117485      0.105014         0.031297        0.012195   \n",
       "557      15.316455      0.156335         0.023665        0.007218   \n",
       "558      15.244908      0.152797         0.022263        0.005468   \n",
       "559      15.163302      0.067038         0.027670        0.008182   \n",
       "560      22.360932      0.139307         0.027681        0.003895   \n",
       "561      22.414212      0.141556         0.028920        0.006761   \n",
       "562      22.564410      0.160787         0.026696        0.007139   \n",
       "563      22.314797      0.165718         0.030094        0.005824   \n",
       "564      22.426342      0.139849         0.039727        0.024441   \n",
       "565      22.408960      0.045368         0.028888        0.003502   \n",
       "566      22.429595      0.112651         0.032670        0.006301   \n",
       "567      22.529099      0.109697         0.030101        0.000020   \n",
       "568      22.436018      0.114281         0.028484        0.003196   \n",
       "569      22.549938      0.088905         0.038344        0.015821   \n",
       "570      22.536223      0.099585         0.030893        0.006781   \n",
       "571      22.495052      0.109282         0.030921        0.004662   \n",
       "572      22.926456      0.135200         0.029686        0.000811   \n",
       "573      23.337700      0.291573         0.034133        0.013574   \n",
       "574      23.142279      0.585276         0.029055        0.008369   \n",
       "575      21.512484      0.390384         0.022600        0.002937   \n",
       "\n",
       "    param_learning_rate param_max_depth param_n_estimators param_reg_alpha  \\\n",
       "0                  0.01               3                100               0   \n",
       "1                  0.01               3                100               0   \n",
       "2                  0.01               3                100               0   \n",
       "3                  0.01               3                100               0   \n",
       "4                  0.01               3                100            0.01   \n",
       "5                  0.01               3                100            0.01   \n",
       "6                  0.01               3                100            0.01   \n",
       "7                  0.01               3                100            0.01   \n",
       "8                  0.01               3                100            0.03   \n",
       "9                  0.01               3                100            0.03   \n",
       "10                 0.01               3                100            0.03   \n",
       "11                 0.01               3                100            0.03   \n",
       "12                 0.01               3                100             0.1   \n",
       "13                 0.01               3                100             0.1   \n",
       "14                 0.01               3                100             0.1   \n",
       "15                 0.01               3                100             0.1   \n",
       "16                 0.01               3                200               0   \n",
       "17                 0.01               3                200               0   \n",
       "18                 0.01               3                200               0   \n",
       "19                 0.01               3                200               0   \n",
       "20                 0.01               3                200            0.01   \n",
       "21                 0.01               3                200            0.01   \n",
       "22                 0.01               3                200            0.01   \n",
       "23                 0.01               3                200            0.01   \n",
       "24                 0.01               3                200            0.03   \n",
       "25                 0.01               3                200            0.03   \n",
       "26                 0.01               3                200            0.03   \n",
       "27                 0.01               3                200            0.03   \n",
       "28                 0.01               3                200             0.1   \n",
       "29                 0.01               3                200             0.1   \n",
       "..                  ...             ...                ...             ...   \n",
       "546                 0.1               6                200               0   \n",
       "547                 0.1               6                200               0   \n",
       "548                 0.1               6                200            0.01   \n",
       "549                 0.1               6                200            0.01   \n",
       "550                 0.1               6                200            0.01   \n",
       "551                 0.1               6                200            0.01   \n",
       "552                 0.1               6                200            0.03   \n",
       "553                 0.1               6                200            0.03   \n",
       "554                 0.1               6                200            0.03   \n",
       "555                 0.1               6                200            0.03   \n",
       "556                 0.1               6                200             0.1   \n",
       "557                 0.1               6                200             0.1   \n",
       "558                 0.1               6                200             0.1   \n",
       "559                 0.1               6                200             0.1   \n",
       "560                 0.1               6                300               0   \n",
       "561                 0.1               6                300               0   \n",
       "562                 0.1               6                300               0   \n",
       "563                 0.1               6                300               0   \n",
       "564                 0.1               6                300            0.01   \n",
       "565                 0.1               6                300            0.01   \n",
       "566                 0.1               6                300            0.01   \n",
       "567                 0.1               6                300            0.01   \n",
       "568                 0.1               6                300            0.03   \n",
       "569                 0.1               6                300            0.03   \n",
       "570                 0.1               6                300            0.03   \n",
       "571                 0.1               6                300            0.03   \n",
       "572                 0.1               6                300             0.1   \n",
       "573                 0.1               6                300             0.1   \n",
       "574                 0.1               6                300             0.1   \n",
       "575                 0.1               6                300             0.1   \n",
       "\n",
       "    param_reg_lambda                                             params  \\\n",
       "0                  0  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "1               0.01  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "2               0.03  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "3                0.1  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "4                  0  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "5               0.01  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "6               0.03  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "7                0.1  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "8                  0  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "9               0.01  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "10              0.03  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "11               0.1  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "12                 0  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "13              0.01  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "14              0.03  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "15               0.1  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "16                 0  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "17              0.01  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "18              0.03  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "19               0.1  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "20                 0  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "21              0.01  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "22              0.03  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "23               0.1  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "24                 0  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "25              0.01  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "26              0.03  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "27               0.1  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "28                 0  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "29              0.01  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "..               ...                                                ...   \n",
       "546             0.03  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "547              0.1  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "548                0  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "549             0.01  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "550             0.03  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "551              0.1  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "552                0  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "553             0.01  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "554             0.03  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "555              0.1  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "556                0  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "557             0.01  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "558             0.03  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "559              0.1  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "560                0  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "561             0.01  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "562             0.03  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "563              0.1  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "564                0  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "565             0.01  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "566             0.03  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "567              0.1  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "568                0  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "569             0.01  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "570             0.03  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "571              0.1  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "572                0  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "573             0.01  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "574             0.03  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "575              0.1  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...   \n",
       "\n",
       "          ...         mean_test_score  std_test_score  rank_test_score  \\\n",
       "0         ...                0.659737        0.017865               85   \n",
       "1         ...                0.659949        0.017392               76   \n",
       "2         ...                0.659101        0.016988              123   \n",
       "3         ...                0.658464        0.017555              145   \n",
       "4         ...                0.659313        0.017447              104   \n",
       "5         ...                0.659313        0.017447              104   \n",
       "6         ...                0.659313        0.017100              104   \n",
       "7         ...                0.659313        0.017310              104   \n",
       "8         ...                0.659313        0.017048              104   \n",
       "9         ...                0.659313        0.018295              104   \n",
       "10        ...                0.659525        0.017657               95   \n",
       "11        ...                0.659737        0.018133               85   \n",
       "12        ...                0.659737        0.017672               85   \n",
       "13        ...                0.659525        0.017223               95   \n",
       "14        ...                0.660373        0.017340               55   \n",
       "15        ...                0.659949        0.017044               76   \n",
       "16        ...                0.659949        0.016142               76   \n",
       "17        ...                0.660373        0.015960               55   \n",
       "18        ...                0.661434        0.015912               19   \n",
       "19        ...                0.661222        0.014903               25   \n",
       "20        ...                0.661646        0.016404               14   \n",
       "21        ...                0.660161        0.014490               65   \n",
       "22        ...                0.660798        0.015648               40   \n",
       "23        ...                0.659949        0.014257               76   \n",
       "24        ...                0.661434        0.015371               19   \n",
       "25        ...                0.661434        0.016555               19   \n",
       "26        ...                0.660161        0.015990               65   \n",
       "27        ...                0.661010        0.014648               30   \n",
       "28        ...                0.661646        0.014585               14   \n",
       "29        ...                0.659949        0.015469               76   \n",
       "..        ...                     ...             ...              ...   \n",
       "546       ...                0.636826        0.010579              526   \n",
       "547       ...                0.636826        0.008338              526   \n",
       "548       ...                0.643403        0.012636              442   \n",
       "549       ...                0.633857        0.011134              556   \n",
       "550       ...                0.642554        0.013320              457   \n",
       "551       ...                0.639160        0.014441              492   \n",
       "552       ...                0.643615        0.006797              436   \n",
       "553       ...                0.635766        0.007073              540   \n",
       "554       ...                0.641493        0.009471              469   \n",
       "555       ...                0.639796        0.009559              488   \n",
       "556       ...                0.638736        0.011027              501   \n",
       "557       ...                0.637463        0.003575              513   \n",
       "558       ...                0.642978        0.012395              449   \n",
       "559       ...                0.636402        0.015584              531   \n",
       "560       ...                0.636402        0.005077              531   \n",
       "561       ...                0.634705        0.007909              546   \n",
       "562       ...                0.636402        0.011442              531   \n",
       "563       ...                0.640857        0.008497              476   \n",
       "564       ...                0.643190        0.013392              446   \n",
       "565       ...                0.631735        0.011552              570   \n",
       "566       ...                0.638948        0.014811              496   \n",
       "567       ...                0.634705        0.009615              546   \n",
       "568       ...                0.637251        0.008747              520   \n",
       "569       ...                0.633008        0.007664              563   \n",
       "570       ...                0.634281        0.006189              551   \n",
       "571       ...                0.633220        0.013721              560   \n",
       "572       ...                0.635766        0.016877              540   \n",
       "573       ...                0.634069        0.006324              553   \n",
       "574       ...                0.637251        0.009889              520   \n",
       "575       ...                0.634493        0.010607              549   \n",
       "\n",
       "     split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0              0.681432            0.681517            0.673827   \n",
       "1              0.681432            0.682312            0.673827   \n",
       "2              0.681698            0.682312            0.674357   \n",
       "3              0.681698            0.681517            0.672501   \n",
       "4              0.682493            0.681517            0.673827   \n",
       "5              0.682493            0.681517            0.673561   \n",
       "6              0.683024            0.680191            0.674092   \n",
       "7              0.681167            0.680986            0.674357   \n",
       "8              0.681963            0.682312            0.673031   \n",
       "9              0.681432            0.681252            0.673561   \n",
       "10             0.681963            0.681517            0.673296   \n",
       "11             0.681698            0.680721            0.674092   \n",
       "12             0.680637            0.682047            0.673561   \n",
       "13             0.680902            0.682047            0.673561   \n",
       "14             0.680902            0.681782            0.672766   \n",
       "15             0.680637            0.682047            0.672501   \n",
       "16             0.696817            0.688146            0.682047   \n",
       "17             0.696552            0.687351            0.682578   \n",
       "18             0.694960            0.687351            0.683373   \n",
       "19             0.695756            0.687881            0.682578   \n",
       "20             0.694960            0.687616            0.682578   \n",
       "21             0.694695            0.687351            0.682047   \n",
       "22             0.695491            0.687616            0.682047   \n",
       "23             0.696021            0.686820            0.682578   \n",
       "24             0.695225            0.687086            0.682312   \n",
       "25             0.695756            0.685760            0.682578   \n",
       "26             0.696021            0.686555            0.680986   \n",
       "27             0.695756            0.687616            0.681517   \n",
       "28             0.695756            0.687616            0.681252   \n",
       "29             0.695491            0.688146            0.682047   \n",
       "..                  ...                 ...                 ...   \n",
       "546            0.981698            0.984619            0.982233   \n",
       "547            0.981698            0.984885            0.982233   \n",
       "548            0.981698            0.984885            0.981702   \n",
       "549            0.981432            0.984619            0.981968   \n",
       "550            0.981698            0.984885            0.981968   \n",
       "551            0.981698            0.984885            0.981968   \n",
       "552            0.981432            0.984885            0.981968   \n",
       "553            0.981698            0.984885            0.981968   \n",
       "554            0.981432            0.984619            0.981968   \n",
       "555            0.981698            0.984885            0.982233   \n",
       "556            0.981432            0.984885            0.982233   \n",
       "557            0.981698            0.984885            0.982233   \n",
       "558            0.981698            0.984885            0.981968   \n",
       "559            0.981698            0.984885            0.981968   \n",
       "560            0.981698            0.984885            0.982233   \n",
       "561            0.981698            0.984885            0.982233   \n",
       "562            0.981698            0.984885            0.982233   \n",
       "563            0.981698            0.984885            0.982233   \n",
       "564            0.981698            0.984885            0.982233   \n",
       "565            0.981698            0.984885            0.982233   \n",
       "566            0.981698            0.984885            0.982233   \n",
       "567            0.981698            0.984885            0.982233   \n",
       "568            0.981698            0.984885            0.982233   \n",
       "569            0.981698            0.984885            0.982233   \n",
       "570            0.981698            0.984885            0.982233   \n",
       "571            0.981698            0.984885            0.982233   \n",
       "572            0.981698            0.984885            0.982233   \n",
       "573            0.981698            0.984885            0.982233   \n",
       "574            0.981698            0.984885            0.982233   \n",
       "575            0.981698            0.984885            0.982233   \n",
       "\n",
       "     split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0              0.681336            0.685578          0.680738         0.003812  \n",
       "1              0.681336            0.686108          0.681003         0.003989  \n",
       "2              0.680011            0.686903          0.681056         0.004053  \n",
       "3              0.679480            0.686903          0.680420         0.004658  \n",
       "4              0.681336            0.686108          0.681056         0.004004  \n",
       "5              0.681336            0.684783          0.680738         0.003792  \n",
       "6              0.680276            0.686638          0.680844         0.004115  \n",
       "7              0.681336            0.686638          0.680897         0.003899  \n",
       "8              0.680806            0.686638          0.680950         0.004427  \n",
       "9              0.682131            0.687169          0.681109         0.004356  \n",
       "10             0.680011            0.686108          0.680579         0.004165  \n",
       "11             0.681336            0.687434          0.681056         0.004237  \n",
       "12             0.680806            0.687434          0.680897         0.004426  \n",
       "13             0.680806            0.687434          0.680950         0.004424  \n",
       "14             0.680806            0.685578          0.680367         0.004181  \n",
       "15             0.681071            0.686108          0.680473         0.004431  \n",
       "16             0.690350            0.696978          0.690868         0.005625  \n",
       "17             0.688229            0.696713          0.690284         0.005529  \n",
       "18             0.689820            0.696713          0.690443         0.004892  \n",
       "19             0.687964            0.696978          0.690231         0.005390  \n",
       "20             0.690085            0.695917          0.690231         0.004902  \n",
       "21             0.690615            0.696182          0.690178         0.005114  \n",
       "22             0.687699            0.696448          0.689860         0.005401  \n",
       "23             0.688759            0.695917          0.690019         0.005254  \n",
       "24             0.689290            0.696713          0.690125         0.005299  \n",
       "25             0.688229            0.696448          0.689754         0.005488  \n",
       "26             0.689024            0.696448          0.689807         0.005860  \n",
       "27             0.688494            0.696448          0.689966         0.005561  \n",
       "28             0.690085            0.697243          0.690390         0.005780  \n",
       "29             0.688494            0.697508          0.690337         0.005566  \n",
       "..                  ...                 ...               ...              ...  \n",
       "546            0.980647            0.983828          0.982605         0.001439  \n",
       "547            0.980912            0.983563          0.982658         0.001409  \n",
       "548            0.980912            0.984093          0.982658         0.001543  \n",
       "549            0.981177            0.983828          0.982605         0.001369  \n",
       "550            0.980912            0.983828          0.982658         0.001468  \n",
       "551            0.980647            0.984093          0.982658         0.001579  \n",
       "552            0.980912            0.984093          0.982658         0.001552  \n",
       "553            0.981177            0.984093          0.982764         0.001453  \n",
       "554            0.980647            0.984093          0.982552         0.001541  \n",
       "555            0.981177            0.984093          0.982817         0.001427  \n",
       "556            0.981177            0.984093          0.982764         0.001472  \n",
       "557            0.980912            0.984093          0.982764         0.001491  \n",
       "558            0.980912            0.984093          0.982711         0.001513  \n",
       "559            0.981177            0.984093          0.982764         0.001453  \n",
       "560            0.981177            0.984093          0.982817         0.001427  \n",
       "561            0.981177            0.984093          0.982817         0.001427  \n",
       "562            0.981177            0.984093          0.982817         0.001427  \n",
       "563            0.981177            0.984093          0.982817         0.001427  \n",
       "564            0.981177            0.984093          0.982817         0.001427  \n",
       "565            0.981177            0.984093          0.982817         0.001427  \n",
       "566            0.981177            0.984093          0.982817         0.001427  \n",
       "567            0.981177            0.984093          0.982817         0.001427  \n",
       "568            0.981177            0.984093          0.982817         0.001427  \n",
       "569            0.981177            0.984093          0.982817         0.001427  \n",
       "570            0.981177            0.984093          0.982817         0.001427  \n",
       "571            0.981177            0.984093          0.982817         0.001427  \n",
       "572            0.981177            0.984093          0.982817         0.001427  \n",
       "573            0.981177            0.984093          0.982817         0.001427  \n",
       "574            0.981177            0.984093          0.982817         0.001427  \n",
       "575            0.981177            0.984093          0.982817         0.001427  \n",
       "\n",
       "[576 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================================================================================================\n",
      "Score: 0.6620484908461158\n",
      "accuracy: 0.6620484908461158\n",
      "precision: 0.6552734375\n",
      "recall: 0.6703296703296703\n",
      "auc: 0.6621256194785606\n",
      "========================================================================================================================================================================================================\n",
      "Rank_diff importance: 0.08269453793764114\n",
      "ytd_Aces%_Stddev_diff importance: 0.026945412158966064\n",
      "ytd_ServesWon%_Stddev_diff importance: 0.02671312354505062\n",
      "careeravg_Sets_Won_diff importance: 0.0696864128112793\n",
      "careeravg_Games_Won_diff importance: 0.028106853365898132\n",
      "careeravg_Aces_diff importance: 0.016724739223718643\n",
      "careeravg_DoubleFaults_diff importance: 0.03159117326140404\n",
      "careeravg_FirstServes_Won_diff importance: 0.0037166085094213486\n",
      "careeravg_FirstServes_In_diff importance: 0.003948896657675505\n",
      "careeravg_SecondServes_Won_diff importance: 0.01904761977493763\n",
      "careeravg_SecondServes_In_diff importance: 0.018583042547106743\n",
      "careeravg_BreakPoints_Won_diff importance: 0.013472706079483032\n",
      "careeravg_BreakPoints_diff importance: 0.01765388995409012\n",
      "careeravg_ReturnPoints_Won_diff importance: 0.014169570058584213\n",
      "careeravg_ReturnPoints_Faced_diff importance: 0.013472706079483032\n",
      "careeravg_TotalPoints_Won_diff importance: 0.003484320593997836\n",
      "careeravg_won_game?_diff importance: 0.05969802662730217\n",
      "careeravg_FirstServes_ratio_diff importance: 0.02020905911922455\n",
      "careeravg_SecondServes_ratio_diff importance: 0.03437862917780876\n",
      "careeravg_BreakPoints_ratio_diff importance: 0.008130080997943878\n",
      "careeravg_ReturnPoints_ratio_diff importance: 0.02857142873108387\n",
      "careeravg_Total_Serves_diff importance: 0.013472706079483032\n",
      "careeravg_Aces%_diff importance: 0.01300812978297472\n",
      "careeravg_ServesWon%_diff importance: 0.02857142873108387\n",
      "ytd_Sets_Won_diff importance: 0.01579558663070202\n",
      "ytd_Games_Won_diff importance: 0.017886178568005562\n",
      "ytd_Aces_diff importance: 0.014401858672499657\n",
      "ytd_DoubleFaults_diff importance: 0.024390242993831635\n",
      "ytd_FirstServes_Won_diff importance: 0.004181184805929661\n",
      "ytd_FirstServes_In_diff importance: 0.021835075691342354\n",
      "ytd_SecondServes_Won_diff importance: 0.008362369611859322\n",
      "ytd_SecondServes_In_diff importance: 0.009059233590960503\n",
      "ytd_BreakPoints_Won_diff importance: 0.012311265803873539\n",
      "ytd_BreakPoints_diff importance: 0.022996515035629272\n",
      "ytd_ReturnPoints_Won_diff importance: 0.011614401824772358\n",
      "ytd_ReturnPoints_Faced_diff importance: 0.006736353039741516\n",
      "ytd_TotalPoints_Won_diff importance: 0.005110336933284998\n",
      "ytd_won_game?_diff importance: 0.019279906526207924\n",
      "ytd_FirstServes_ratio_diff importance: 0.039721254259347916\n",
      "ytd_SecondServes_ratio_diff importance: 0.0329849012196064\n",
      "ytd_BreakPoints_ratio_diff importance: 0.018815331161022186\n",
      "ytd_ReturnPoints_ratio_diff importance: 0.03182346001267433\n",
      "ytd_Total_Serves_diff importance: 0.02926829271018505\n",
      "ytd_Aces%_diff importance: 0.005342625081539154\n",
      "ytd_ServesWon%_diff importance: 0.018118467181921005\n",
      "Player1fg importance: 0.018583042547106743\n",
      "Player2fg importance: 0.015331010334193707\n"
     ]
    }
   ],
   "source": [
    "#training and then testing a basic model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "fullX = X.copy()\n",
    "if 'Player1' in X.columns:\n",
    "    X.drop(['Player1','Player2','datetime'],axis=1,inplace=True)\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,Y,test_size=.3)\n",
    "params ={'max_depth':[3,4,5,6],\n",
    "         'n_estimators':[100,200,300],\n",
    "         'learning_rate':[.01,.03,.1],\n",
    "         'reg_alpha':[0,.01,.03,.1],\n",
    "         'reg_lambda':[0,.01,.03,.1]\n",
    "        }\n",
    "estimator = xgb.XGBClassifier(random_state=123)\n",
    "tuneparam = GridSearchCV(estimator,params,n_jobs=-1,cv=5)\n",
    "print(\"tuning model\")\n",
    "tuneparam.fit(Xtrain,ytrain)\n",
    "\n",
    "model = tuneparam.best_estimator_\n",
    "best_params = tuneparam.best_params_\n",
    "cvtable = tuneparam.cv_results_\n",
    "cvdf = pd.DataFrame(cvtable)\n",
    "display(cvdf[cvdf['rank_test_score']==1])\n",
    "\n",
    "def get_scores(predy,ytest):\n",
    "    import sklearn.metrics as metrics\n",
    "    acc = metrics.accuracy_score(ytest,predy)\n",
    "    prec = metrics.precision_score(ytest,predy)\n",
    "    recall = metrics.recall_score(ytest,predy)\n",
    "    auc = metrics.roc_auc_score(ytest,predy)\n",
    "    return {'accuracy':acc,'precision':prec,'recall':recall,'auc':auc}\n",
    "score = model.score(Xtest,ytest)\n",
    "predy = model.predict(Xtest)\n",
    "\n",
    "scoresdict = get_scores(predy,ytest)\n",
    "print(\"=\"*200)\n",
    "print(\"Score: {}\".format(score))\n",
    "for key,value in scoresdict.items():\n",
    "    print(\"{}: {}\".format(key,value))\n",
    "\n",
    "print(\"=\"*200)\n",
    "for idx, col in enumerate(Xtrain.columns.tolist()):\n",
    "    print(\"{} importance: {}\".format(col,model.feature_importances_[idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about a model just trained using Ranked Diff? (curious to see how much predictive power rank has)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning model\n",
      "========================================================================================================================================================================================================\n",
      "Score: 0.6472043542800594\n",
      "accuracy: 0.6472043542800594\n",
      "precision: 0.6316270566727605\n",
      "recall: 0.6903096903096904\n",
      "auc: 0.6476058255470021\n",
      "========================================================================================================================================================================================================\n",
      "Rank_diff importance: [1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Hugh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "rankXtrain = Xtrain.loc[:,'Rank_diff'].values.reshape(Xtrain.shape[0],1)\n",
    "rankXtest = Xtest.loc[:,'Rank_diff'].values.reshape(Xtest.shape[0],1)\n",
    "\n",
    "# print(rankXtrain.shape)\n",
    "params ={'max_depth':[4,5,6],\n",
    "         'n_estimators':[100,200,300],\n",
    "         'learning_rate':[.01,.03,.1],\n",
    "        }\n",
    "estimator = xgb.XGBClassifier(random_state=123)\n",
    "tuneparam = GridSearchCV(estimator,params,n_jobs=-1)\n",
    "print(\"tuning model\")\n",
    "tuneparam.fit(rankXtrain,ytrain)\n",
    "\n",
    "model2 = tuneparam.best_estimator_\n",
    "best_params2 = tuneparam.best_params_\n",
    "\n",
    "score2 = model2.score(rankXtest,ytest)\n",
    "predy2 = model2.predict(rankXtest)\n",
    "scoresdict2 = get_scores(predy2,ytest)\n",
    "\n",
    "print(\"=\"*200)\n",
    "print(\"Score: {}\".format(score2))\n",
    "for key,value in scoresdict2.items():\n",
    "    print(\"{}: {}\".format(key,value))\n",
    "\n",
    "print(\"=\"*200)\n",
    "print(\"{} importance: {}\".format('Rank_diff',model2.feature_importances_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'reg_alpha': 0, 'reg_lambda': 0.01}\n",
      "{'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "print(best_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
